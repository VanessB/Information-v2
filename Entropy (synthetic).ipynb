{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy (synthetic)\n",
    "\n",
    "Эксперименты с оценкой энтропии для синтетических данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PuuYTaasyqC"
   },
   "source": [
    "# Преамбула"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J20_kxWGua1g"
   },
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knCL6YcRtDSI"
   },
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKI49Wt7s1ZH",
    "outputId": "00b0c2c1-a14d-4681-b725-966bd57299dc"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81zMD0EitGlJ"
   },
   "source": [
    "### Math, Numpy, Scipy, Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TrbCI8-s4re"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GwNnxNiDgYw"
   },
   "source": [
    "### Matplotlib, Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0SjY2FyDgiY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWH6JIAJtbs3"
   },
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rb9G9YxtfD3"
   },
   "outputs": [],
   "source": [
    "# Деревья.\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# Метрика.\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "# Метод главных компонент.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Выбор модели по кросс-валидации (поиск по сетке).\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLVaeOz9tbwI"
   },
   "source": [
    "### Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5R5GjsuMtPe4"
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "n_jobs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCTOH5CQuULh"
   },
   "source": [
    "### Json, CSV, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwC7bZldt4qY"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9zP5A4nufLs"
   },
   "source": [
    "## Вспомогательное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flPbS2ebuY7h"
   },
   "outputs": [],
   "source": [
    "# Информация об опыте.\n",
    "info = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RyvEh9bulAV"
   },
   "outputs": [],
   "source": [
    "def normalize_uint8(data, label):\n",
    "    \"\"\"Нормализация: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(data, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5xA0W2DvIBq"
   },
   "outputs": [],
   "source": [
    "def imshow_array(array):\n",
    "    \"\"\"Отображение массива нормированных пикселей.\"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow((255.0 * array).astype(np.uint8), cmap=plt.get_cmap(\"gray\"), vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5OjeuhXvP6O"
   },
   "outputs": [],
   "source": [
    "def dataset_Y_to_X(X, Y):\n",
    "    \"\"\"Поменять у датасета пары (X, Y) на (X, X) (нужно, например, для обучения автоэнкодера).\"\"\"\n",
    "    return X, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo0MXHDowRLZ"
   },
   "outputs": [],
   "source": [
    "def concave_loss(y_true, y_pred):\n",
    "    \"\"\"Вогнутая функция потерь, дающая более четкие изображения при обучении.\"\"\"\n",
    "    delta = tf.keras.backend.abs(y_true - y_pred)\n",
    "    squared = tf.keras.backend.square(y_true - y_pred)\n",
    "    return tf.keras.backend.mean(delta - 0.5 * squared, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9o4czLSwxib"
   },
   "source": [
    "## Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSdv1fxZwt8N",
    "outputId": "c08303d3-5680-4b43-f4f0-26fa82612a4a"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tneJ2JaEwztO"
   },
   "outputs": [],
   "source": [
    "#path = \"/content/drive/My Drive/Information_v2/\"\n",
    "path = \"/tf/home/sirius/Projects/Information-v2/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxwU2N_pxJP5"
   },
   "source": [
    "# Синтетические данные\n",
    "\n",
    "Для первоначальных экспериментов данные синтезируются путем сэмплирования точек из некоторого распределения с последующим отображением на некоторое многообразие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eDZuNXnxBr-"
   },
   "outputs": [],
   "source": [
    "dataset_dim = 8  # Размерность данных.\n",
    "latent_dim  = 2  # Реальная (скрытая) размерность данных.\n",
    "final_noize_stdev = 0.0 # Стандартное отклонение шума, складываемого с выходом функции.\n",
    "samples_number = 60000 # Размер выборки.\n",
    "tests_number   = 10000 # Размер тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQK4o5df_Jki"
   },
   "outputs": [],
   "source": [
    "experiments_path = path + \"synthetic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odGeIptZCgsn"
   },
   "source": [
    "### Распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGboVNtaCuVq"
   },
   "outputs": [],
   "source": [
    "class rv_multidim:\n",
    "    \"\"\"Базовый класс для многомерных распределений (структура взята из scipy.stats.rv_continuous)\"\"\"\n",
    "\n",
    "    def __init__(self, momtype=1, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None):\n",
    "        if badvalue is None:\n",
    "            self.badvalue = np.nan\n",
    "        else:\n",
    "            self.badvalue = badvalue\n",
    "\n",
    "        self.name = name\n",
    "        self.longname = longname\n",
    "        self.shapes = shapes\n",
    "        self.extradoc = extradoc\n",
    "        self.seed = seed\n",
    "\n",
    "    def rvs(self, *args, **kwds):\n",
    "        \"\"\"Сэмплирование.\"\"\"\n",
    "        return self._rvs(*args, **kwds)\n",
    "\n",
    "    def pdf(self, x, *args, **kwds):\n",
    "        \"\"\"Функция плотности.\"\"\"\n",
    "        return self._pdf(x, *args, **kwds)\n",
    "    \n",
    "    def logpdf(self, x, *args, **kwds):\n",
    "        \"\"\"Логарифм функции плотности.\"\"\"\n",
    "        return np.log(self.pdf(x, *args, **kwds))\n",
    "\n",
    "    def cdf(self, x, *args, **kwds):\n",
    "        \"\"\"Функция распределения.\"\"\"\n",
    "        return 1.0 - self.pdf(x, *args, **kwds)\n",
    "\n",
    "    def logcdf(self, x, *args, **kwds):\n",
    "        \"\"\"Логарифм функции распределения.\"\"\"\n",
    "        return np.log(self.cdf(x, *args, **kwds))\n",
    "\n",
    "    def entropy(self, *args, **kwds):\n",
    "        \"\"\"Энтропия.\"\"\"\n",
    "        return self._entropy(*args, **kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfmgnEY3I5aK"
   },
   "outputs": [],
   "source": [
    "# переделанный класс для строк: поддерживает работу с несколькими массивами\n",
    "\n",
    "class horizontal_stripes(rv_multidim):\n",
    "    \"\"\"Несколько полос с равномерным распределением.\"\"\"\n",
    "\n",
    "    def __init__(self, loc_x=np.array([-5, -1, 3]), scale_x=np.array([1, 1, 1]), loc_y=-np.pi, scale_y=2.0*np.pi, seed=None):\n",
    "        super(some_hor_stripes, self).__init__(name=\"some distributed stripes\", \n",
    "                                               longname=\"some distributed stripes\",\n",
    "                                               shapes=\"loc_x, scale_x\", seed=seed)\n",
    "\n",
    "        assert len(ranks) != 0, 'Список ranks не должен быть пустым'\n",
    "\n",
    "\n",
    "        self._loc_x = loc_x\n",
    "        self._scale_x = scale_x\n",
    "        self._loc_y = loc_y\n",
    "        self._scale_y = scale_y\n",
    "\n",
    "\n",
    "    def _rvs(self, size=1, random_state=None):\n",
    "\n",
    "        number = sps.randint(low=0, high=3).rvs(1, random_state=None)\n",
    "        return np.vstack((sps.uniform(loc=self._loc_x[number], scale=self._scale_x[number]).rvs(size, random_state=random_state), \n",
    "                         sps.uniform(loc=self._loc_y, scale=self._scale_y).rvs(size, random_state=random_state))).T\n",
    "\n",
    "    def _entropy(self):\n",
    "        return np.log(self._loc_x.sum() * self._scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPEP0mBdMo-9"
   },
   "outputs": [],
   "source": [
    "class three_uniform_stripes(rv_multidim):\n",
    "    \"\"\"Три полосы с равномерным распределением.\"\"\"\n",
    "\n",
    "    def __init__(self, loc_x=-np.pi, scale_x=2.0*np.pi, loc_y1=-5, scale_y1=2, loc_y2=-1, scale_y2=2, loc_y3=3, scale_y3=2, seed=None):\n",
    "        super(three_uniform_stripes, self).__init__(name=\"Three uniformly distributed stripes\", longname=\"Three uniformly distributed stripes\",\n",
    "                                                    shapes=\"loc_x1, scale_x1, loc_x2, scale_x2, loc_x3, scale_x3\", seed=seed)\n",
    "        \n",
    "        self._loc_x    = loc_x\n",
    "        self._scale_x  = scale_x\n",
    "        self._loc_y1   = loc_y1\n",
    "        self._scale_y1 = scale_y1\n",
    "        self._loc_y2   = loc_y2\n",
    "        self._scale_y2 = scale_y2\n",
    "        self._loc_y3   = loc_y3\n",
    "        self._scale_y3 = scale_y3\n",
    "\n",
    "        self._stripe_x  = sps.uniform(self._loc_x,  self._scale_x)\n",
    "        self._stripe_y1 = sps.uniform(self._loc_y1, self._scale_y1)\n",
    "        self._stripe_y2 = sps.uniform(self._loc_y2, self._scale_y2)\n",
    "        self._stripe_y3 = sps.uniform(self._loc_y3, self._scale_y3)\n",
    "\n",
    "    def _rvs(self, size=1, random_state=None):\n",
    "        X1 = self._stripe_x.rvs(size, random_state)\n",
    "        \n",
    "        X01 = self._stripe_y1.rvs(size, random_state)\n",
    "        X02 = self._stripe_y2.rvs(size, random_state)\n",
    "        X03 = self._stripe_y3.rvs(size, random_state)\n",
    "\n",
    "        X0 = np.concatenate((X01, X02, X03), axis = None)\n",
    "        X2 = np.random.choice(X0, size = size, replace = False)\n",
    "\n",
    "        X = np.column_stack((X1,X2))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _entropy(self):\n",
    "        return np.log((self._scale_y1 + self._scale_y2 + self._scale_y3) * self._scale_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class One_Ring(rv_multidim):\n",
    "    \"\"\"Кольцо, полученное из прямоугольника с равномерным распределением.\"\"\"\n",
    "\n",
    "    def __init__(self, loc_x=-np.pi, scale_x=2.0*np.pi, less_rad = 1, bigg_rad = 2, seed=None):\n",
    "        super(One_Ring, self).__init__(name=\"One Ring that rules them all\", longname=\"One Ring that rules them all\",\n",
    "                                                    shapes=\"loc_x, scale_x, less_rad, bigg_rad\", seed=seed)\n",
    "        \n",
    "        assert ((loc_x >= -np.pi) and (scale_x <= 2.0 * np.pi) and (less_rad > 0) and (bigg_rad > less_rad))\n",
    "\n",
    "        self._loc_x    = loc_x\n",
    "        self._scale_x  = scale_x\n",
    "        self._loc_y   = less_rad\n",
    "        self._scale_y = bigg_rad - less_rad\n",
    "\n",
    "        self._uniform_x = sps.uniform(self._loc_x, self._scale_x)\n",
    "        self._uniform_y = sps.uniform(self._loc_y, self._scale_y)\n",
    "\n",
    "    def _rvs(self, size=1, random_state=None):\n",
    "        X01 = self._uniform_x.rvs(size, random_state)        \n",
    "        X02 = self._uniform_y.rvs(size, random_state)\n",
    "        \n",
    "        X1 = X02 * np.cos(X01)\n",
    "        X2 = X02 * np.sin(X01)\n",
    "\n",
    "        X = np.column_stack((X1,X2))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _entropy(self):\n",
    "        r = self._loc_y\n",
    "        delta_r = self._scale_y\n",
    "        R = r + delta_r\n",
    "        delta_phi = self._scale_x\n",
    "        \n",
    "        return ( R * (np.log(R) - 1.0) - r * (np.log(r) - 1.0) ) / delta_r + np.log(delta_r * delta_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rv_id_ensemble(rv_multidim):\n",
    "    \"\"\" Многомерное распределение, независимое по каждой координате.\"\"\"\n",
    "\n",
    "    def __init__(self, rv_list):\n",
    "        self.rv_list = rv_list\n",
    "\n",
    "    def _rvs(self, size=1, random_state=None):\n",
    "        XI = []\n",
    "        \n",
    "        for i in range(0, len(self.rv_list)):\n",
    "            XI.append(self.rv_list[i].rvs(size, random_state))\n",
    "            X = np.column_stack(XI)\n",
    "        return X\n",
    "\n",
    "    def _entropy(self):\n",
    "        entr = 0.0\n",
    "        \n",
    "        for i in range(0, len(self.rv_list)):\n",
    "            entr += self.rv_list[i].entropy()\n",
    "            \n",
    "        return entr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h_mKSKeClI3"
   },
   "source": [
    "### Отображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_smooth:\n",
    "    \"\"\"Базовый класс для кусочно гладких отображений\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim  = None\n",
    "        self.output_dim = None\n",
    "\n",
    "    def map(self, x):\n",
    "        \"\"\"Отобразить x.\"\"\"\n",
    "        return self._map(x)\n",
    "\n",
    "    def jac(self, x):\n",
    "        \"\"\"Матрица Якоби.\"\"\"\n",
    "        return self._jac(x)\n",
    "\n",
    "    def defc(self, x):\n",
    "        \"\"\"Коэффициент растяжения.\"\"\"\n",
    "        return self._defc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ансамбль преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_ensemble(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Ансамбль отображений.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mappings_list):\n",
    "        self.input_dim = 0\n",
    "        self.output_dim = 0\n",
    "        for i in range(0, len(mappings_list)):\n",
    "            self.input_dim += mappings_list[i].input_dim\n",
    "            self.output_dim += mappings_list[i].output_dim\n",
    "        self.mappings_list = mappings_list\n",
    "\n",
    "    def _map(self, x):\n",
    "        y = np.zeros(self.output_dim)\n",
    "\n",
    "        taken_x = 0\n",
    "        taken_y = 0\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):\n",
    "            y[taken_y:taken_y + self.mappings_list[i].output_dim] = self.mappings_list[i].map(x[taken_x:taken_x + self.mappings_list[i].input_dim])\n",
    "            \n",
    "            taken_x += self.mappings_list[i].input_dim\n",
    "            taken_y += self.mappings_list[i].output_dim\n",
    "            \n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        jacs = []\n",
    "        \n",
    "        taken_x = 0\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):    \n",
    "            jacs.append(self.mappings_list[i].jac(np.array(x[taken_x:taken_x + self.mappings_list[i].input_dim])))\n",
    "            taken_x += self.mappings_list[i].input_dim        \n",
    "                \n",
    "        return spl.block_diag(*jacs)\n",
    "\n",
    "    def _defc(self, x):\n",
    "        defcs = []\n",
    "        \n",
    "        taken_x = 0\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):            \n",
    "            defcs.append(self.mappings_list[i].defc(x[taken_x:taken_x + self.mappings_list[i].input_dim]))\n",
    "            taken_x += self.mappings_list[i].input_dim        \n",
    "              \n",
    "        defc = 1.0\n",
    "        \n",
    "        for i in range(0, len(defcs)):\n",
    "            defc *= defcs[i]\n",
    "            \n",
    "        return defc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параллельная система преобразований."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_parallel(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая отображение маломерного многообразия на многомерное.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mappings_list):\n",
    "        self.input_dim = 0\n",
    "        self.output_dim = 0\n",
    "        for i in range(0, len(mappings_list)):\n",
    "            if (self.input_dim <= mappings_list[i].input_dim):\n",
    "                self.input_dim = mappings_list[i].input_dim\n",
    "            self.output_dim += mappings_list[i].output_dim\n",
    "        self.mappings_list = mappings_list\n",
    "\n",
    "    def _map(self, x):\n",
    "        y = np.zeros(self.output_dim)\n",
    "\n",
    "        taken_y = 0\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):\n",
    "            y[taken_y:taken_y + self.mappings_list[i].output_dim] = self.mappings_list[i].map(x[0:self.mappings_list[i].input_dim])\n",
    "            \n",
    "            taken_y += self.mappings_list[i].output_dim\n",
    "            \n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        jac = self.mappings_list[0].jac(np.array(x[0:self.mappings_list[0].input_dim]))\n",
    "                \n",
    "        for i in range(1, len(self.mappings_list)):    \n",
    "            jac = np.concatenate((jac, self.mappings_list[i].jac(np.array(x[0:self.mappings_list[i].input_dim]))), axis=1)\n",
    "            \n",
    "        return jac\n",
    "\n",
    "    def _defc(self, x):\n",
    "        J = self.jac(x)\n",
    "        return np.sqrt(npl.det(J @ J.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Последовательная система преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_sequential(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая композицию функций.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mappings_list):\n",
    "        check = True\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list) - 1):\n",
    "            check = check and (self.mappings_list[i].output_dim == self.mappings_list[i+1].input_dim)\n",
    "            \n",
    "        assert (check == True)\n",
    "        \n",
    "        self.input_dim = mappings_list[0].input_dim\n",
    "        self.output_dim = mappings_list[-1]\n",
    "        self.mappings_list = mappings_list\n",
    "\n",
    "    def _map(self, x):\n",
    "        y = x\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):\n",
    "            y = self.mappings_list[i].map(y)\n",
    "            \n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        jac = np.identity(self.mappings_list[0].input_dim)\n",
    "        y = x\n",
    "        \n",
    "        for i in range(0, len(self.mappings_list)):        \n",
    "            jac = jac @ self.mappings_list[i].jac(y)\n",
    "            y = self.mappings_list[i].map(y)\n",
    "            \n",
    "        return jac\n",
    "\n",
    "    def _defc(self, x):        \n",
    "        J = self.jac(x)\n",
    "        return np.sqrt(npl.det(J @ J.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полуцилиндр\n",
    "\n",
    "$$\n",
    "(x',y',z') = g_1(x,y): \\quad \\begin{matrix} x' = \\begin{cases}\n",
    "\\sin(x), \\; x \\in \\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right] \\\\\n",
    "sign(x), \\; else\n",
    "\\end{cases} \\\\\n",
    "y' = y \\\\\n",
    "z' = \\begin{cases}\n",
    "\\cos(x), \\; x \\in \\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right] \\\\\n",
    "-\\left| x - sign(x) \\frac{\\pi}{2} \\right|, \\; else\n",
    "\\end{cases}\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_semicylinder(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая отображение плоскости на бесконечный цилиндр с основанием \"полукруг + два параллельных луча\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim  = 2\n",
    "        self.output_dim = 3\n",
    "\n",
    "    def _map(self, x):\n",
    "        y = np.zeros(3)\n",
    "\n",
    "        if ((x[0] >= - np.pi / 2) and (x[0] <= np.pi / 2)):\n",
    "            y[0] = np.sin(x[0])\n",
    "            y[1] = x[1]\n",
    "            y[2] = np.cos(x[0])\n",
    "        else:\n",
    "            y[0] = np.sign(x[0])\n",
    "            y[1] = x[1]\n",
    "            y[2] = -np.abs(x[0] - (np.sign(x[0]) * np.pi / 2))\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        if ((x[0] >= -np.pi / 2) and (x[0] <= np.pi/2)):\n",
    "            return np.array([[np.cos(x[0]), 0.0, -np.sin(x[0])],\n",
    "                             [0.0, 1.0, 0.0]])\n",
    "        else:\n",
    "            return np.array([[np.cos(x[0]), 0.0, -np.sin(x[0])],\n",
    "                             [0.0, 1.0, 0.0]])\n",
    "        \n",
    "    def _defc(self, x):\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бинокль\n",
    "\n",
    "$$\n",
    "(x',y',z') = g_2(x,y): \\quad \\begin{matrix} x' = sign(x)\\left(1-\\cos(x)\\right)\\\\\n",
    "y' = y \\\\\n",
    "z' = -\\sin(x)\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_bicylinder(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая отображение полосы (-2pi, 2pi) x \\RR на \"двойную трубку\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim  = 2\n",
    "        self.output_dim = 3\n",
    "\n",
    "    def _map(self, x):\n",
    "        assert ((x[0] >= -2.0 * np.pi) and (x[0] <= 2.0 * np.pi))\n",
    "\n",
    "        y = np.zeros(3)\n",
    "        \n",
    "        y[0] = np.sign(x[0]) * (1 - np.cos(x[0]))\n",
    "        y[1] = x[1]\n",
    "        y[2] = - np.sin(x[0])\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        assert ((x[0] >= -2.0 * np.pi) and (x[0] <= 2.0 * np.pi))\n",
    "\n",
    "        return np.array([[np.sin(x[0]) * np.sign(x[0]), 0.0, -np.cos(x[0])],\n",
    "                         [0.0, 1.0, 0.0]])\n",
    "        \n",
    "    def _defc(self, x):\n",
    "        assert ((x[0] >= -2.0 * np.pi) and (x[0] <= 2.0 * np.pi))\n",
    "\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сфера (\"обратная\" проекция Меркатора)\n",
    "\n",
    "$$\n",
    "(x',y',z') = g_3(x,y): \\quad \\begin{matrix} \n",
    "x' = \\cos x \\cos\\left(\\arctan\\left((\\sinh y\\right)\\right) \\\\\n",
    "y' = \\sin x \\cos\\left(\\arctan\\left((\\sinh y\\right)\\right) \\\\\n",
    "z' = \\sin\\left(\\arctan\\left((\\sinh y\\right)\\right)\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_inverse_Mercator(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая отображение полосы (-pi, pi] x \\RR на сферу единичного радиуса.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim  = 2\n",
    "        self.output_dim = 3\n",
    "\n",
    "    def _map(self, x):\n",
    "        assert ((x[0] >= -np.pi) and (x[0] <= np.pi))\n",
    "        \n",
    "        y = np.zeros(3)\n",
    "        \n",
    "        y[0] = np.cos(x[0]) * np.cos(np.arctan(np.sinh(x[1])))\n",
    "        y[1] = np.sin(x[0]) * np.cos(np.arctan(np.sinh(x[1])))\n",
    "        y[2] = np.sin(np.arctan(np.sinh(x[1])))\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        assert ((x[0] >= -np.pi) and (x[0] <= np.pi))\n",
    "\n",
    "        return np.array([[-np.sin(x[0]) * np.cos(np.arctan(np.sinh(x[1]))), np.cos(x[0]) * np.cos(np.arctan(np.sinh(x[1]))), 0.0],\n",
    "                         [-np.sinh(x[1]) * np.cosh(x[1]) * np.cos(x[0]) / np.power((np.power(np.sinh(x[1]), 2) + 1),(3 / 2)), -np.sinh(x[1]) * np.cosh(x[1]) * np.sin(x[0]) / np.power((np.power(np.sinh(x[1]), 2) + 1),(3 / 2)), -np.cosh(x[1]) / np.power((np.power(np.sinh(x[1]), 2) + 1),(3 / 2))]])\n",
    "        \n",
    "    def _defc(self, x):\n",
    "        assert ((x[0] >= -np.pi) and (x[0] <= np.pi))\n",
    "        \n",
    "        return np.cos(np.arctan(np.sinh(x[1]))) / np.cosh(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Плохой\" (п.в. дифференцируемый) полуцилиндр\n",
    "\n",
    "$$\n",
    "(x',y',z') = g_4(x,y): \\quad \\begin{matrix} x' = \\begin{cases}\n",
    "\\sin(x), \\; x \\in \\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right] \\\\\n",
    "sign(x) \\left(\\left|x\\right|-\\frac{\\pi}{2}+1\\right), \\; else\n",
    "\\end{cases} \\\\\n",
    "y' = y \\\\\n",
    "z' = \\begin{cases}\n",
    "\\cos(x), \\; x \\in \\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right] \\\\\n",
    "0, \\; else\n",
    "\\end{cases}\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mapping_bad_semicylinder(mapping_smooth):\n",
    "    \"\"\"\n",
    "    Функция, задающая отображение плоскости на бесконечный цилиндр с основанием \"полукруг + два луча в стороны\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim  = 2\n",
    "        self.output_dim = 3\n",
    "\n",
    "    def _map(self, x):\n",
    "        y = np.zeros(3)\n",
    "\n",
    "        if ((x[0] >= - np.pi / 2) and (x[0] <= np.pi / 2)):\n",
    "            y[0] = np.sin(x[0])\n",
    "            y[1] = x[1]\n",
    "            y[2] = np.cos(x[0])\n",
    "        else:\n",
    "            y[0] = np.sign(x[0]) * (np.abs(x[0]) - (np.pi / 2) + 1)\n",
    "            y[1] = x[1]\n",
    "            y[2] = 0\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _jac(self, x):\n",
    "        if ((x[0] >= -np.pi / 2) and (x[0] <= np.pi/2)):\n",
    "            return np.array([[np.cos(x[0]), 0.0, -np.sin(x[0])],\n",
    "                             [0.0, 1.0, 0.0]])\n",
    "        else:\n",
    "            return np.array([[1.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0]])\n",
    "\n",
    "    def _defc(self, x):\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D4QTSroJPXR"
   },
   "source": [
    "### Выбор случайной величины и отображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ_mG9OeCvm1"
   },
   "outputs": [],
   "source": [
    "random_variables = [rv_id_ensemble([sps.uniform(-np.pi, 2.0 * np.pi), sps.norm()]),\n",
    "                    rv_id_ensemble([sps.semicircular(-np.pi, 2.0 * np.pi), sps.norm()]),\n",
    "                    One_Ring(less_rad = 4.0, bigg_rad = 6.0),\n",
    "                    three_uniform_stripes()]\n",
    "mappings = [mapping_semicylinder(), mapping_bicylinder(), mapping_inverse_Mercator(), mapping_bad_semicylinder()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x68Z9AwpAqE5"
   },
   "outputs": [],
   "source": [
    "# НОМЕР ИСХОДНОГО РАСПРЕДЕЛЕНИЯ.\n",
    "# #\n",
    "# #\n",
    "random_variable_index = 3\n",
    "# #\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj1GnkqWAbma"
   },
   "outputs": [],
   "source": [
    "# НОМЕР ФУНКЦИИ, ЗАДАЮЩЕЙ МНОГООБРАЗИЕ.\n",
    "# #\n",
    "# #\n",
    "mapping_index = 2\n",
    "# #\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWuXJNQ6C_bT"
   },
   "outputs": [],
   "source": [
    "random_variable = random_variables[random_variable_index - 1]\n",
    "mapping = mappings[mapping_index - 1]\n",
    "\n",
    "# Проверка входной размерности.\n",
    "assert latent_dim == mapping.input_dim\n",
    "\n",
    "true_entropy = random_variable.entropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nM9z7mipDQND"
   },
   "source": [
    "### Генерация набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hM8IKyNZD4tr"
   },
   "outputs": [],
   "source": [
    "# Матрица поворота и повышения размерности.\n",
    "Q = sps.ortho_group.rvs(dim = dataset_dim)\n",
    "#Q = np.eye(dataset_dim)\n",
    "transform = Q[:,:mapping.output_dim]\n",
    "\n",
    "#print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn_tuKO73HSp"
   },
   "outputs": [],
   "source": [
    "def get_samples(random_variable, mapping, samples_number, dataset_dim, transform_matrix, final_noize_stdev = 0.05):\n",
    "    \"\"\"\n",
    "    Генерация набора данных.\n",
    "    \"\"\"\n",
    "\n",
    "    # Данные во внутреннем представлении.\n",
    "    #np.random.seed(42)\n",
    "    X = random_variable.rvs(samples_number)\n",
    "    \n",
    "    # Отображение шума в пространство большей размерности.\n",
    "    Y = np.zeros((samples_number, dataset_dim))\n",
    "    noize = sps.norm(loc=0, scale=final_noize_stdev)\n",
    "    for i in range(samples_number):\n",
    "        Y[i] = transform_matrix @ mapping.map(X[i]) + noize.rvs(dataset_dim)\n",
    "            \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDkJjM2CDTuJ"
   },
   "outputs": [],
   "source": [
    "samples = get_samples(random_variable, mapping, samples_number, dataset_dim, transform, final_noize_stdev)\n",
    "tests   = get_samples(random_variable, mapping, tests_number,   dataset_dim, transform, final_noize_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J_18kMWsERTp",
    "outputId": "a98fd5ee-c238-4a73-d9fe-0428ba074967"
   },
   "outputs": [],
   "source": [
    "draw_pair_plot = True\n",
    "if draw_pair_plot:\n",
    "    pp = sns.pairplot(pd.DataFrame(samples[:1000]), height = 2.0, aspect=1.6,\n",
    "                      plot_kws=dict(edgecolor=\"k\", linewidth=0.0, alpha=0.1, size=0.01, s=0.01),\n",
    "                      diag_kind=\"kde\", diag_kws=dict(shade=True))\n",
    "\n",
    "    fig = pp.fig\n",
    "    fig.subplots_adjust(top=0.93, wspace=0.3)\n",
    "    t = fig.suptitle('Pairwise Plots', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pRyKwjKCqml"
   },
   "source": [
    "### Путь к результатам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBi5v6hSAk1K"
   },
   "outputs": [],
   "source": [
    "dataset_path = experiments_path + \"rv_\" + str(random_variable_index) + \"_map_\" + str(mapping_index) + \"/\" + str(latent_dim) + \"_\" + str(dataset_dim) + '/' + (\"%.3e\" % final_noize_stdev) + \"/\" + str(samples_number) + \"_\" + str(tests_number) + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R73vj8c3x3-Y"
   },
   "source": [
    "# Оценка энтропии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2coUXxYyAVx"
   },
   "source": [
    "## Автокодировщик\n",
    "\n",
    "Сжатие данных предлагается делать автокодировщиком.\n",
    "Для архитектуры специфицируется только формат входных данных, а также размерность внутреннего представления (кодов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aa1TECWvxuEF"
   },
   "outputs": [],
   "source": [
    "# РАЗМЕРНОСТЬ КОДА.\n",
    "# #\n",
    "# #\n",
    " \n",
    "codes_dim = 2\n",
    "\n",
    "# #\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3McJCha_b_G"
   },
   "outputs": [],
   "source": [
    "# Число эпох для обучения.\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOu7nB9gx9vH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "full_path = dataset_path + \"autoencoders/\" + str(codes_dim) + \"_\" + str(epochs) + \"/\"\n",
    "os.makedirs(full_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lwIjSKL_gMv"
   },
   "outputs": [],
   "source": [
    "info['dataset_dim'] = dataset_dim\n",
    "info['latent_dim'] = latent_dim\n",
    "\n",
    "info['samples_number'] = samples_number\n",
    "info['tests_number'] = tests_number\n",
    "\n",
    "info['codes_dim'] = codes_dim\n",
    "info['epochs'] = epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45W1qKkoB90y"
   },
   "source": [
    "### Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2475m-kB1mm"
   },
   "outputs": [],
   "source": [
    "def dense_autoencoder(shape_input, dimension):\n",
    "    # Инициализация весов.\n",
    "    init = tf.keras.initializers.RandomNormal(stddev = 0.02)\n",
    "\n",
    "    # Входные данные генератора / выборки.\n",
    "    input_layer = tf.keras.layers.Input(shape_input)\n",
    "    next_layer = input_layer\n",
    "    next_layer = tf.keras.layers.GaussianNoise(0.05)(next_layer)\n",
    "\n",
    "    # 1 блок слоёв.\n",
    "    next_layer = tfa.layers.SpectralNormalization(tf.keras.layers.Dense(32, kernel_initializer = init),\n",
    "                                                  power_iterations = 8)(next_layer)\n",
    "    next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "\n",
    "    # 2 блок слоёв.\n",
    "    next_layer = tfa.layers.SpectralNormalization(tf.keras.layers.Dense(16, kernel_initializer = init),\n",
    "                                                  power_iterations = 8)(next_layer)\n",
    "    next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "    \n",
    "    # 3 блок слоёв.\n",
    "    #next_layer = tf.keras.layers.Dense(8, kernel_initializer = init)(next_layer)\n",
    "    #next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "    \n",
    "    # Бутылочное горлышко.\n",
    "    next_layer = tfa.layers.SpectralNormalization(tf.keras.layers.Dense(dimension),\n",
    "                                                  power_iterations = 8)(next_layer)\n",
    "    bottleneck = tf.keras.layers.Activation('tanh', name='bottleneck')(next_layer)\n",
    "\n",
    "    # Модель кодировщика.\n",
    "    encoder = tf.keras.Model(input_layer, bottleneck)\n",
    "\n",
    "    # Начало модели декодировщика.\n",
    "    input_code_layer = tf.keras.layers.Input((dimension))\n",
    "    next_layer = input_code_layer\n",
    "\n",
    "    # 3 блок слоёв.\n",
    "    #next_layer = tf.keras.layers.Dense(8, kernel_initializer = init)(next_layer)\n",
    "    #next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "    \n",
    "    # 2 блок слоёв.\n",
    "    next_layer = tf.keras.layers.Dense(16, kernel_initializer = init)(next_layer)\n",
    "    next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "\n",
    "    # 1 блок слоёв.\n",
    "    next_layer = tf.keras.layers.Dense(32, kernel_initializer = init)(next_layer)\n",
    "    next_layer = tf.keras.layers.LeakyReLU(alpha=0.2)(next_layer)\n",
    "    \n",
    "    # 0 блок слоёв.\n",
    "    next_layer = tf.keras.layers.Dense(shape_input[0])(next_layer) # Подразумевается, что вход - всё равно вектор.\n",
    "    #next_layer = tf.keras.layers.Activation('tanh')(next_layer)\n",
    "    \n",
    "    output_layer = next_layer\n",
    "\n",
    "    \n",
    "    # Модель.\n",
    "    decoder = tf.keras.models.Model(input_code_layer, output_layer) # Декодировщик.\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "\n",
    "    # Компиляция модели.\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    autoencoder.compile(loss = 'mse', optimizer = opt, loss_weights = [1.0])\n",
    "    \n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzOjEmMjCCWS"
   },
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmzV6titB6zT"
   },
   "outputs": [],
   "source": [
    "#encoder = tf.keras.models.load_model(full_path + \"encoder.h5\")\n",
    "#decoder = tf.keras.models.load_model(full_path + \"decoder.h5\")\n",
    "#autoencoder = autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "#autoencoder.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), loss_weights = [1.0])\n",
    "\n",
    "#with open(full_path + 'info.json', 'r') as fp:\n",
    "#    info = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld3eyuWPCHtW"
   },
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder = dense_autoencoder((dataset_dim,), codes_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_callback = autoencoder.fit(samples, samples, epochs=epochs, validation_data=(tests, tests), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fB0qcPxALn0F"
   },
   "outputs": [],
   "source": [
    "# Сохранение динамики loss-функции.\n",
    "loss_history = np.array(history_callback.history[\"loss\"])\n",
    "val_loss_history = np.array(history_callback.history[\"val_loss\"])\n",
    "\n",
    "np.savetxt(full_path + \"loss.csv\", loss_history, delimiter=\"\\n\")\n",
    "np.savetxt(full_path + \"val_loss.csv\", val_loss_history, delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfZfumkbM4E_"
   },
   "outputs": [],
   "source": [
    "# Сохранение средних итоговых значений функции потерь.\n",
    "last_n = 20\n",
    "last_loss = np.array(loss_history[-last_n:])\n",
    "last_loss_mean = np.mean(last_loss)\n",
    "last_loss_std = np.std(last_loss)\n",
    "\n",
    "last_val_loss = np.array(val_loss_history[-last_n:])\n",
    "last_val_loss_mean = np.mean(last_val_loss)\n",
    "last_val_loss_std = np.std(last_val_loss)\n",
    "\n",
    "info['last_loss_mean'] = last_loss_mean\n",
    "info['last_loss_std'] = last_loss_std\n",
    "info['last_val_loss_mean'] = last_val_loss_mean\n",
    "info['last_val_loss_std'] = last_val_loss_std\n",
    "\n",
    "with open(dataset_path + \"losses.csv\", 'a+') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow([codes_dim, last_loss_mean, last_loss_std])\n",
    "\n",
    "with open(dataset_path + \"val_losses.csv\", 'a+') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow([codes_dim, last_val_loss_mean, last_val_loss_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQxF6KcgNag-",
    "outputId": "21f60548-9dd3-4430-a27e-3e871a431cfe"
   },
   "outputs": [],
   "source": [
    "# Сохранение моделей.\n",
    "autoencoder.save(full_path + \"autoencoder.h5\")\n",
    "encoder.save(full_path + \"encoder.h5\")\n",
    "decoder.save(full_path + \"decoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuImkbabNcqj"
   },
   "outputs": [],
   "source": [
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPMRQmWmNjIS"
   },
   "source": [
    "### Получение кодов всех элементов набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mksJnyPiNkhD"
   },
   "outputs": [],
   "source": [
    "codes = np.array(encoder.predict(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EMu1RqxN7vj"
   },
   "outputs": [],
   "source": [
    "codes_pca_dim = codes_dim\n",
    "PCA_codes = PCA(n_components=codes_pca_dim, whiten=True)\n",
    "codes_pca = np.array(PCA_codes.fit_transform(codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8qbWLPNO5fg"
   },
   "source": [
    "### KDE для кодов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYPLhT5mO58e"
   },
   "outputs": [],
   "source": [
    "# Загрузка параметров KDE.\n",
    "\n",
    "#with open(full_path + 'info.json', 'r') as fp:\n",
    "#    info = json.load(fp)\n",
    "\n",
    "#kde_codes = KernelDensity(bandwidth=info['bandwidth'], kernel='gaussian')\n",
    "#kde_codes.fit(codes_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMOLm6vsO7Kb"
   },
   "outputs": [],
   "source": [
    "def smart_gridsearch(begin, end, resolution = 7, rel_x_epsilon = 0.01, rtol = 0.001, n_jobs = 2, cv = 5):\n",
    "    while True:\n",
    "        grid = np.logspace(np.log10(begin), np.log10(end), resolution)\n",
    "        print(\"Поиск по сетке: \", grid)\n",
    "        params = {'bandwidth': grid}\n",
    "        \n",
    "        grid_search = GridSearchCV(KernelDensity(rtol = rtol), params, n_jobs = n_jobs, verbose = 10, cv = cv)\n",
    "        grid_search.fit(codes_pca)\n",
    "        \n",
    "        if grid_search.best_index_ == 0:\n",
    "            begin *= begin / end\n",
    "            end = grid[1]\n",
    "        elif grid_search.best_index_ == resolution - 1:\n",
    "            end *= end / begin\n",
    "            begin = grid[-2]\n",
    "        else:\n",
    "            begin = grid[grid_search.best_index_ - 1]\n",
    "            end = grid[grid_search.best_index_ + 1]\n",
    "\n",
    "            if end - begin < rel_x_epsilon * grid[grid_search.best_index_]:\n",
    "                return grid_search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVCcZMpjPII5",
    "outputId": "3648b7da-ec10-446c-8ff0-1dee7f369aa9"
   },
   "outputs": [],
   "source": [
    "KDE_codes = smart_gridsearch(0.05, 0.2, n_jobs = n_jobs).best_estimator_\n",
    "KDE_codes.set_params(rtol = 0.0)\n",
    "print(KDE_codes.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90JoA1fZPLM8"
   },
   "outputs": [],
   "source": [
    "info['bandwidth'] = KDE_codes.get_params()['bandwidth']\n",
    "\n",
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)\n",
    "\n",
    "with open(dataset_path + \"bandwidth.csv\", 'a+') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow([codes_dim, info['bandwidth']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtQMUyL7PTvt"
   },
   "source": [
    "## Подсчёт энтропии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hFnw6XaPXnb"
   },
   "outputs": [],
   "source": [
    "def _loo_step(bandwidth, samples, i):\n",
    "    loo_samples = samples\n",
    "    np.delete(loo_samples, i)\n",
    "    \n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(loo_samples)\n",
    "    return kde.score_samples([samples[i]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB5i2VmjPcub"
   },
   "outputs": [],
   "source": [
    "def entropy_leave_one_out_parallel(path, bandwidth, samples, n_jobs = 2, first_N = None, parts = 10, recover_saved = False):\n",
    "    \"\"\"\n",
    "    Параллельное вычисление оценки энтропии методом убрать-один-элемент.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создание временных папок для сохранения прогресса.\n",
    "    parts_path = path + \"LOO_PARTS/\"\n",
    "    os.makedirs(parts_path, exist_ok=True)\n",
    "\n",
    "    # Если дано first_N, энтропия будет оцениваться только на первых first_N элементах.\n",
    "    N = 0\n",
    "    if first_N is None:\n",
    "        N = len(samples)\n",
    "    else:\n",
    "        N = first_N\n",
    "\n",
    "    # Число частей и массив, их содержащий.\n",
    "    N_per_part = N // parts\n",
    "    log_probs = []\n",
    "\n",
    "    # Восстанавливаем прогресс, если требуется.\n",
    "    recovered_parts = 0\n",
    "    if recover_saved:\n",
    "        for filename in os.listdir(parts_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                log_probs.append(np.loadtxt(parts_path + filename))\n",
    "                recovered_parts += 1\n",
    "\n",
    "    print(\"Восстановлено блоков данных: %d\" % recovered_parts)\n",
    "\n",
    "    # Подсчёт логарифма вероятности в точках.\n",
    "    for part in range(recovered_parts, parts):\n",
    "        log_probs.append(\n",
    "            np.array(\n",
    "                Parallel(n_jobs = n_jobs, verbose = 10, batch_size = 8)(\n",
    "                    delayed(_loo_step)(bandwidth, samples, i) for i in range(part * N_per_part, min((part + 1) * N_per_part, N))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        np.savetxt(parts_path + str(part) + \".csv\", log_probs[part], delimiter=\"\\n\")\n",
    "    \n",
    "    # Объединение в один массив.\n",
    "    log_prob = np.concatenate(log_probs)\n",
    "\n",
    "    # Суммирование и нахождение стандартного отклонения.\n",
    "    average = -math.fsum(log_prob) / N    \n",
    "    squared_deviations = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        squared_deviations[i] = (log_prob[i] - average)**2\n",
    "    standard_deviation = np.sqrt(math.fsum(squared_deviations) / (N * (N - 1)))\n",
    "        \n",
    "    return average, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvhNZC1IPiVO",
    "outputId": "96dfe559-ee14-4712-ae44-f8e76aac951d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_entropy, latent_entropy_error = entropy_leave_one_out_parallel(full_path, KDE_codes.get_params()['bandwidth'], codes_pca, n_jobs = n_jobs, recover_saved = False)\n",
    "print(\"LH: %f, errLH: %f\" % (latent_entropy, latent_entropy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duowAmegPkzY"
   },
   "outputs": [],
   "source": [
    "info['latent entropy'] = latent_entropy\n",
    "info['latent entropy error'] = latent_entropy_error\n",
    "\n",
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fKF66FcPmAy"
   },
   "outputs": [],
   "source": [
    "with open(dataset_path + \"entropy.csv\", 'a+') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow([codes_dim, info['latent entropy'], info['latent entropy error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYmf7pj6YOcP"
   },
   "outputs": [],
   "source": [
    "def model_jac(x, model, m, n):\n",
    "    \"\"\"\n",
    "    Вычисление матрицы Якоби модели в точке.\n",
    "    \n",
    "    x - точка.\n",
    "    model - модель.\n",
    "    m - размерность входа.\n",
    "    n - размерность выхода.\n",
    "    \"\"\"\n",
    "    \n",
    "    variables = [tf.Variable([[x[j]]]) for j in range(m)]\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as t:\n",
    "        t.watch(variables)\n",
    "        z = tf.concat(variables, 1)\n",
    "        f = [model(z)[0][i] for i in range(n)]\n",
    "\n",
    "    J = np.zeros((m, n))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            J[j][i] = t.gradient(f[i], variables[j]).numpy()\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SY6yX8irXna6"
   },
   "outputs": [],
   "source": [
    "def defc_from_jac(J):\n",
    "    \"\"\"\n",
    "    Вычисление коэффициента растяжения для матрицы Якоби.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(J.shape) == 2\n",
    "    return np.sqrt(np.linalg.det(J @ J.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lP440XTulLNF"
   },
   "outputs": [],
   "source": [
    "def _defc_step(sample, model, m, n):\n",
    "    return np.log(defc_from_jac(model_jac(sample, model, m, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdEkmydBj2fq"
   },
   "outputs": [],
   "source": [
    "def transform_entropy_nonparallel(path, samples, model, m, n, first_N = None, parts = 100, recover_saved = False):\n",
    "    \"\"\"\n",
    "    Однопоточное вычисление изменения энтропии под действием декодера.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создание временных папок для сохранения прогресса.\n",
    "    parts_path = path + \"TE_PARTS/\"\n",
    "    os.makedirs(parts_path, exist_ok=True)\n",
    "\n",
    "    # Если дано first_N, энтропия будет оцениваться только на первых first_N элементах.\n",
    "    N = 0\n",
    "    if first_N is None:\n",
    "        N = len(samples)\n",
    "    else:\n",
    "        N = first_N\n",
    "\n",
    "    # Число частей и массив, их содержащий.\n",
    "    N_per_part = N // parts\n",
    "    log_defcs = []\n",
    "\n",
    "    # Восстанавливаем прогресс, если требуется.\n",
    "    recovered_parts = 0\n",
    "    if recover_saved:\n",
    "        for filename in os.listdir(parts_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                log_defcs.append(np.loadtxt(parts_path + filename))\n",
    "                recovered_parts += 1\n",
    "\n",
    "    print(\"Восстановлено блоков данных: %d\" % recovered_parts)\n",
    "\n",
    "    # Подсчёт логарифма вероятности в точках.\n",
    "    for part in range(recovered_parts, parts):\n",
    "        print(\"Новый блок: %d\" % part)\n",
    "        log_defcs.append(\n",
    "            np.array([_defc_step(samples[i], model, m, n) for i in range(part * N_per_part, min((part + 1) * N_per_part, N))])\n",
    "            )\n",
    "        np.savetxt(parts_path + str(part) + \".csv\", log_defcs[part], delimiter=\"\\n\")\n",
    "    \n",
    "    # Объединение в один массив.\n",
    "    log_defc = np.concatenate(log_defcs)\n",
    "\n",
    "    # Суммирование и нахождение стандартного отклонения.\n",
    "    average = math.fsum(log_defc) / N    \n",
    "    squared_deviations = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        squared_deviations[i] = (log_defc[i] - average)**2\n",
    "    standard_deviation = np.sqrt(math.fsum(squared_deviations) / (N * (N - 1)))\n",
    "        \n",
    "    return average, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tlGygUXnJMU"
   },
   "outputs": [],
   "source": [
    "transform_entropy, transform_entropy_error = transform_entropy_nonparallel(full_path, codes, decoder, codes_dim, dataset_dim, recover_saved = False)\n",
    "print(\"TH: %f, errTH: %f\" % (transform_entropy, transform_entropy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPbZFirnnljW"
   },
   "outputs": [],
   "source": [
    "info['transform entropy'] = transform_entropy\n",
    "info['transform entropy error'] = transform_entropy_error\n",
    "\n",
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5UgdsOMnsW7"
   },
   "outputs": [],
   "source": [
    "with open(dataset_path + \"entropy.csv\", 'a+') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow([codes_dim, info['transform entropy'], info['transform entropy error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBw5gOcqIF00"
   },
   "outputs": [],
   "source": [
    "# Коэффициент растяжения при денормализации.\n",
    "PCA_codes_defc = np.abs(np.linalg.det( PCA_codes.inverse_transform(np.eye(codes_pca_dim)) -\n",
    "                                       PCA_codes.inverse_transform(np.zeros((codes_pca_dim, codes_pca_dim))) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkjQc-SVIV_Q"
   },
   "outputs": [],
   "source": [
    "# Соответствующая энтропия.\n",
    "PCA_codes_transform_entropy = np.log(PCA_codes_defc)\n",
    "\n",
    "print(\"PCA_TH: %f\" % (PCA_codes_transform_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['PCA transform entropy'] = PCA_codes_transform_entropy\n",
    "\n",
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzRnFJODT5Kh"
   },
   "outputs": [],
   "source": [
    "# Итоговая оценка энтропии.\n",
    "entropy = latent_entropy + transform_entropy + PCA_codes_transform_entropy\n",
    "entropy_error = latent_entropy_error + transform_entropy_error\n",
    "\n",
    "print(\"H: %f, errH: %f\" % (entropy, entropy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['entropy'] = entropy\n",
    "info['entropy error'] = entropy_error\n",
    "\n",
    "# Сохранение информации.\n",
    "with open(full_path + 'info.json', 'w') as fp:\n",
    "    json.dump(info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifY4lCrVZogt"
   },
   "outputs": [],
   "source": [
    "print(\"Итоговый результат:\")\n",
    "print(\"Оценка: %f\\nИстинное значение: %f\\nОшибка: %.3e\" % (entropy, true_entropy, entropy - true_entropy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Information v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
